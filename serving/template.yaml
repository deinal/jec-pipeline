apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  name: MODEL_NAME
  namespace: NAMESPACE
spec:
  predictor:
    serviceAccountName: sa
    triton:
      storageUri: STORAGE_URI
      args: 
        - --strict-model-config=false
        - --log-verbose=1
      resources:
        limits:
          cpu:     2
          memory:  4Gi
        requests:
          cpu:      1
          memory:   10Mi
